{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "Implementar um jogo onde devemos pegar uma caixa numa determinada posição e soltá-la em outra posição utilizando um algoritmo de Q-learning.\n",
    "\n",
    "# Configuração inicial e propriedades\n",
    "Iremos implementar um tabuleiro bidimensional (campo) com as seguintes especificações:\n",
    "> tamanho do tabuleiro quadrado. Neste caso é 10 x 10;\n",
    "\n",
    "> posição da caixa. Ou seja, onde devemos pegá-la;\n",
    "\n",
    "> posição onde devemos soltar a caixa;\n",
    "\n",
    "> posição que começaremos no campo;\n",
    "\n",
    "> Se temos com a caixa. Inicialmente não.\n",
    "\n",
    "# Regras\n",
    "1. Iremos continuar o jogo até que ele não termine. Ou seja, além da recompensa/punição, devemos retornar também False para cada ação. Pois True indica que o jogo terminou, o que acontecerá apenas quando estivermos com a caixa e soltarmos ela na posição especificada;\n",
    "\n",
    "2. Podemos soltar a caixa em posição inválida.\n",
    "\n",
    "# Algoritmo\n",
    "> Se andar para uma posição inválida, punir em -10;\n",
    "\n",
    "> Se andar para uma posição válida, punir em -1 (não podemos recompensar isso pois isso incentivaria andar infinitamente pelo campo);\n",
    "\n",
    "> Se tentar pegar a caixa e já estivermos com ela na mão, punir em -10. Senão (não temos a caixa), se a caixa não estiver em nossa posição e quisermos pegá-la, punir em -10. Caso contrário, recompensar em 20 (porque achou a caixa);\n",
    "\n",
    "> Se tentar soltar a caixa e não estivermos com ela na mão, punir em -10. Senão (temos a caixa), se não for o lugar de soltar a caixa e quisermos soltá-la, punir em -10. Caso contrário, recompensar em 20 e terminar o jogo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Campo:\n",
    "    def __init__(self, tamanho, posicao_pegar_caixa, posicao_soltar_caixa, posicao_inicial):\n",
    "        ''' \n",
    "        Um estado é um inteiro que representa uma determinada matriz. A matriz é composta por 5 vetores: \n",
    "        a coordenada x da posição do jogador, vai de 0 a 9;\n",
    "        a coordenada y da posição do jogador, vai de 0 a 9;\n",
    "        a coordenada x da posição da caixa, vai de 0 a 9;\n",
    "        a coordenada y da posição da caixa, vai de 0 a 9;\n",
    "        se temos ou não a caixa, um boolenano.\n",
    "\n",
    "        Logo, é uma matriz de dimensão 10 x 10 x 10 x 10 x 2.\n",
    "        '''\n",
    "        self.tamanho = tamanho # tamanho do campo bidimensional\n",
    "        self.posicao_caixa = posicao_pegar_caixa # posição onde está a caixa. Está inicialmente onde devemos pegá-la\n",
    "        self.posicao_soltar_caixa = posicao_soltar_caixa # posição onde devemos soltar a caixa\n",
    "        self.posicao = posicao_inicial # posição onde estamos. Começamos na posição inicial\n",
    "        self.caixa_no_carro = False # não começamos com a caixa\n",
    "\n",
    "    def get_numero_estados(self):\n",
    "        ''' 2*10^4 '''\n",
    "        return self.tamanho**4*2\n",
    "\n",
    "    def get_estado(self):\n",
    "        ''' Retorna um inteiro que representa uma configuração do jogo '''\n",
    "        estado  = self.posicao[0]       *self.tamanho**3*2 # representa a coordenada x da posição do jogador;\n",
    "        estado += self.posicao[1]       *self.tamanho**2*2 # representa a coordenada y da posição do jogador;\n",
    "        estado += self.posicao_caixa[0] *self.tamanho**1*2 # representa a coordenada x da posição da caixa;\n",
    "        estado += self.posicao_caixa[1]                 *2 # representa a coordenada y da posição da caixa;\n",
    "        if self.caixa_no_carro:\n",
    "            estado += 1 # representa um estado em que temos a caixa\n",
    "\n",
    "        # Dessa forma, temos um mapeamento da matriz a um único inteiro para cada estado.\n",
    "        # Embora nem todos os inteiros de 0 a 2*10^4 sejam abrangidos, a cada matriz é mapeado um inteiro,\n",
    "        # o que satisfaz nosso objetivo.\n",
    "\n",
    "        return estado\n",
    "    \n",
    "    def agir(self, acao):\n",
    "        (x,y) = self.posicao\n",
    "\n",
    "        if acao == 0: # ir para o sul\n",
    "            if y == 0:\n",
    "                return - 10, False # não anda e pune\n",
    "            else:\n",
    "                self.posicao = (x,y-1) # desce 1 casa\n",
    "                return -1, False\n",
    "        elif acao == 1: # ir para o norte\n",
    "            if y == self.tamanho - 1:\n",
    "                return - 10, False # não anda e pune\n",
    "            else:\n",
    "                self.posicao = (x,y+1) # sobe 1 casa\n",
    "                return -1, False\n",
    "        elif acao == 2: # ir para o leste\n",
    "            if x == self.tamanho - 1:\n",
    "                return - 10, False # não anda e pune\n",
    "            else:\n",
    "                self.posicao = (x+1,y) # 1 casa para direita\n",
    "                return -1, False\n",
    "        elif acao == 3: # ir para o oeste\n",
    "            if x == 0:\n",
    "                return - 10, False # não anda e pune\n",
    "            else:\n",
    "                self.posicao = (x-1,y) # 1 casa para esquerda\n",
    "                return -1, False\n",
    "        elif acao == 4: # pegar a caixa\n",
    "            if self.caixa_no_carro:\n",
    "                return -10, False\n",
    "            elif self.posicao_caixa != self.posicao: # na aula, ao invés de \"self.posicao\" é usado \"(x,y)\"\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.caixa_no_carro = True\n",
    "                return 20, False\n",
    "        elif acao == 5: # soltar a caixa\n",
    "            if not self.caixa_no_carro:\n",
    "                return -10, False\n",
    "            elif self.posicao_soltar_caixa != self.posicao: # se soltarmos a caixa e não estivermos na posição correta de soltá-la\n",
    "                self.posicao_caixa = self.posicao\n",
    "                self.caixa_no_carro = False\n",
    "                return -10, False\n",
    "            else:\n",
    "                return 20, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exemplo de implementação manual com todos os movimentos corretos\n",
    "# campo = Campo(10, (0,0), (9,9), (9,0))\n",
    "\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "# campo.agir(3)\n",
    "\n",
    "# campo.agir(4)\n",
    "\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "# campo.agir(2)\n",
    "\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "# campo.agir(1)\n",
    "\n",
    "# campo.posicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87203"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def solucao_ingenua():\n",
    "    tamanho = 10\n",
    "    posicao_inicio_caixa = (0,0)\n",
    "    posicao_soltar_caixa = (9,9)\n",
    "    posicao_inicial = (9,0)\n",
    "\n",
    "    campo = Campo(tamanho,posicao_inicio_caixa,posicao_soltar_caixa, posicao_inicial)\n",
    "    terminado = False\n",
    "    passos = 0\n",
    "\n",
    "    while not terminado:\n",
    "        acao = random.randint(0,5)\n",
    "        recompensa, terminado = campo.agir(acao)\n",
    "        passos += 1\n",
    "    return passos\n",
    "\n",
    "solucao_ingenua()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "tamanho = 10\n",
    "posicao_caixa = (0,0)\n",
    "posicao_soltar_caixa = (9,9)\n",
    "posicao_inicio = (0,9)\n",
    "campo = Campo(tamanho, posicao_caixa, posicao_soltar_caixa, posicao_inicio)\n",
    "\n",
    "numero_estados = campo.get_numero_estados() # representa todas as configurações possíveis\n",
    "numero_acoes = 6 # representa todas as ações possíveis\n",
    "q_table = np.zeros((numero_estados, numero_acoes)) # shape = (20000, 6)\n",
    "\n",
    "epsilon = 0.1 # probabilidade de executar uma ação aleatória\n",
    "alpha = 0.1 # probababilidade de mudança de um registro da Q-table, ou seja, a taxa de aprendizagem\n",
    "gamma = 0.6 # fator de desconto usado para\n",
    "\n",
    "for _ in range(1000):\n",
    "    campo = Campo(tamanho, posicao_caixa, posicao_soltar_caixa, posicao_inicio)\n",
    "    feito = False\n",
    "\n",
    "    while not feito:\n",
    "        estado = campo.get_estado()\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            # representa uma ação aleatória dentre os 6 já implementados na classe Campo.\n",
    "            acao = random.randint(0,5)\n",
    "        else:\n",
    "            # representa a melhor ação de um determinado estado até aquele momento\n",
    "            acao = np.argmax(q_table[estado])\n",
    "\n",
    "        recompensa, feito = campo.agir(acao)\n",
    "        \n",
    "        # A melhor recompensa do novo estado\n",
    "        # Ou seja, a recompensa da ação que possui a maior recompensa dentre as 6 disponíveis\n",
    "        novo_estado = np.max(q_table[campo.get_estado()]) \n",
    "        \n",
    "        # Implementar a fórmula que atualiza a q_table\n",
    "        q_table[estado,acao] = (1 - alpha)*q_table[estado,acao] + alpha*(recompensa + gamma*novo_estado - q_table[estado,acao])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aprendizado_por_reforco(): # a q-table 'memoriza' as melhores ações para cada estado\n",
    "    epsilon = 0.1; alpha = 0.1; gamma = 0.6; feito = False;passos = 0\n",
    "    campo = Campo(tamanho, posicao_caixa, posicao_soltar_caixa, posicao_inicio)\n",
    "\n",
    "    while not feito:\n",
    "        estado = campo.get_estado()\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            acao = random.randint(0,5)\n",
    "        else:\n",
    "            acao = np.argmax(q_table[estado])\n",
    "\n",
    "        recompensa, feito = campo.agir(acao)\n",
    "        novo_estado = np.max(q_table[campo.get_estado()])\n",
    "        q_table[estado,acao] = (1 - alpha)*q_table[estado,acao] + alpha*(recompensa + gamma*novo_estado - q_table[estado,acao])\n",
    "\n",
    "        passos += 1\n",
    "    return passos\n",
    "\n",
    "aprendizado_por_reforco()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a0ffeee1815c3f95f74238463e6183bf0a4f2a738e213d1e2ad861e9b4757a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
